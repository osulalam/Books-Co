# Books-Co

## Summary
This was a project I had to do for a technical take-home interview. I've decided to not elaborate on it since the company may reuse this problem for another candidate. As you can tell, I didn't have enough time to finish so I didn't explain/describe very much throughout my analysis. 

Had I had more time, I would have done more exploratory data analysis, clustering to understand the customer profiles a bit further - which would then be used as a method of dimensionality reduction to feed into our model. I used XGBoost for this binary classification problem because from my previous experience in participating in Kaggle Competitions, its predictions are very accurate - but could also lead to overfitting. 

If I had more time, I'd conduct a grid search for the appropriate parameters that would optimize the model and reduce overfitting. I'd also like to dig a little deeper into model validation and ensemble methods through model stacking.  

#### Personal Note
Since I started coding in Python, I haven't been too familiar with the proper forms of documentation. I became aware of it after joining the Meetup group [Write the Docs Los Angeles](https://www.meetup.com/Write-the-Docs-Los-Angeles/). Learning how to code in Python, experimenting with different machine learning algorithms, and generally immersing myself in the computer engineering community has been a lot of fun for me these past couple of months. Like with anything else, there's been its ups and downs but overall it's definitely been a net positive for me. This field is very new and exciting to me, and I can't wait to see what the future holds for me.  
